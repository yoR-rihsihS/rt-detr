{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd759313",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home1/shishirm/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "\n",
    "from rtdetr import RTDETR, RTDETRPostProcessor, box_iou\n",
    "from rtdetr import COCODataset, collate_fn, get_valid_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56423b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda:0\"\n",
    "CHECKPOINT_PATH = \"./saved/rtdetr_r18_50.pth\"\n",
    "CONFIG_PATH = \"./rtdetr_r18.json\"\n",
    "cfg = json.load(open(CONFIG_PATH, \"r\"))\n",
    "\n",
    "APPLY_NMS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ca80ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RTDETR(\n",
    "    num_classes = cfg['num_classes'],\n",
    "    backbone_model = cfg['backbone_model'],\n",
    "    hidden_dim = cfg['hidden_dim'], \n",
    "    nhead = cfg['nhead'], \n",
    "    ffn_dim = cfg['ffn_dim'], \n",
    "    num_encoder_layers = cfg['num_encoder_layers'],\n",
    "    expansion_factor= cfg['expansion_factor'],\n",
    "    aux_loss = cfg['aux_loss'],\n",
    "    num_queries = cfg['num_queries'],\n",
    "    num_decoder_points = cfg['num_decoder_points'],\n",
    "    num_denoising = cfg['num_denoising'],\n",
    "    num_decoder_layers = cfg['num_decoder_layers'],\n",
    "    dropout = cfg['dropout'],\n",
    "    multi_scale= cfg['multi_scale'],\n",
    "    num_bottleneck_blocks= cfg['num_bottleneck_blocks'],\n",
    ")\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, map_location=\"cpu\", weights_only=True)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "output_processor = RTDETRPostProcessor(num_classes=cfg['num_classes'], num_queries=cfg['num_queries']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53f0b18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Samples in Validation Set: 5000\n"
     ]
    }
   ],
   "source": [
    "val_set = COCODataset(image_dir='./data/val2017/', annot_path='./data/annotations/instances_val2017.json', transforms=get_valid_transforms())\n",
    "print(\"Total Samples in Validation Set:\", len(val_set))\n",
    "\n",
    "val_loader = DataLoader(val_set, batch_size=cfg['batch_size'], shuffle=False, num_workers=3, collate_fn=collate_fn, prefetch_factor=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cef0d7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cxcywh_norm_to_xyxy_abs(boxes, im_size=640):\n",
    "    \"\"\"\n",
    "    Scales normalised (cx, cy, w, h) to absolute (x1, y1, x2, y2) in pixels.\n",
    "    \"\"\"\n",
    "    cx, cy, w, h = boxes.unbind(-1)\n",
    "    cx *= im_size\n",
    "    cy *= im_size\n",
    "    w  *= im_size\n",
    "    h  *= im_size\n",
    "    x1 = cx - 0.5 * w\n",
    "    y1 = cy - 0.5 * h\n",
    "    x2 = cx + 0.5 * w\n",
    "    y2 = cy + 0.5 * h\n",
    "    return torch.stack([x1, y1, x2, y2], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc6e194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_box_iou(boxes1, boxes2):\n",
    "#     \"\"\"\n",
    "#     Compute IoU between two sets of boxes, boxes1 and boxes2.\n",
    "#     boxes1: Tensor[N,4], boxes2: Tensor[M,4] (format: x1,y1,x2,y2)\n",
    "#     Returns: Tensor[N,M] IoU matrix\n",
    "#     \"\"\"\n",
    "#     area1 = (boxes1[:, 2] - boxes1[:, 0]).clamp(min=0) * (boxes1[:, 3] - boxes1[:, 1]).clamp(min=0)\n",
    "#     area2 = (boxes2[:, 2] - boxes2[:, 0]).clamp(min=0) * (boxes2[:, 3] - boxes2[:, 1]).clamp(min=0)\n",
    "\n",
    "#     lt = torch.max(boxes1[:, None, :2], boxes2[:, :2])  # [N,M,2]\n",
    "#     rb = torch.min(boxes1[:, None, 2:], boxes2[:, 2:])  # [N,M,2]\n",
    "\n",
    "#     wh = (rb - lt).clamp(min=0)  # [N,M,2]\n",
    "#     inter = wh[:, :, 0] * wh[:, :, 1]  # [N,M]\n",
    "\n",
    "#     union = area1[:, None] + area2 - inter\n",
    "#     iou = inter / (union + 1e-6)  # add epsilon for stability\n",
    "\n",
    "#     return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba54ddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms_per_class(boxes, scores, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Performs NMS for boxes and scores belonging to a single class.\n",
    "    Args:\n",
    "        boxes: Tensor[N, 4], xyxy format absolute\n",
    "        scores: Tensor[N]\n",
    "        iou_threshold: float\n",
    "    Returns:\n",
    "        keep_indices: Tensor of indices kept after NMS\n",
    "    \"\"\"\n",
    "    if boxes.numel() == 0:\n",
    "        return torch.empty((0,), dtype=torch.long, device=boxes.device)\n",
    "    order = scores.argsort(descending=True)\n",
    "    keep_mask = torch.ones_like(scores, dtype=torch.bool)\n",
    "\n",
    "    for i in range(order.numel()):\n",
    "        idx = order[i]\n",
    "        if not keep_mask[idx]:\n",
    "            continue\n",
    "        \n",
    "        # Get the indices of the boxes to compare against\n",
    "        compare_indices = order[i+1:]\n",
    "        compare_indices = compare_indices[keep_mask[compare_indices]]\n",
    "        if compare_indices.numel() == 0:\n",
    "            break\n",
    "        ious, _ = box_iou(boxes[idx].unsqueeze(0), boxes[compare_indices])\n",
    "\n",
    "        suppress_mask = ious[0] > iou_threshold\n",
    "        indices_to_suppress = compare_indices[suppress_mask]\n",
    "        keep_mask[indices_to_suppress] = False\n",
    "\n",
    "    return torch.where(keep_mask)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fdee523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_nms(predictions, iou_threshold=0.5, im_size=640):\n",
    "    \"\"\"\n",
    "    Performs NMS on a batch of predictions.\n",
    "    Args:\n",
    "        predictions: list of dicts (batch size B), each dict:\n",
    "            \"boxes\": tensor [k,4] normalized (cx, cy, w, h)\n",
    "            \"scores\": tensor [k]\n",
    "            \"labels\": tensor [k]\n",
    "        iou_threshold: IoU threshold for suppression\n",
    "        im_size: int or tuple(int,int) image dimension(s) for conversion\n",
    "    Returns:\n",
    "        list of dicts with filtered predictions after NMS\n",
    "    \"\"\"\n",
    "    nms_batch = []\n",
    "    for pred in predictions:\n",
    "        boxes_norm = pred[\"boxes\"]\n",
    "        scores = pred[\"scores\"]\n",
    "        labels = pred[\"labels\"]\n",
    "\n",
    "        if boxes_norm.numel() == 0:\n",
    "            nms_batch.append({\n",
    "                \"boxes\": boxes_norm.new_empty((0, 4)),\n",
    "                \"scores\": scores.new_empty((0,)),\n",
    "                \"labels\": labels.new_empty((0,), dtype=labels.dtype)\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        boxes = cxcywh_norm_to_xyxy_abs(boxes_norm.clone(), im_size)\n",
    "        keep_indices = []\n",
    "        unique_labels = labels.unique()\n",
    "\n",
    "        for c in unique_labels:\n",
    "            cls_mask = (labels == c)\n",
    "            original_indices = cls_mask.nonzero(as_tuple=True)[0]\n",
    "\n",
    "            kept_local_indices = nms_per_class(boxes[cls_mask], scores[cls_mask], iou_threshold)\n",
    "            keep_indices.append(original_indices[kept_local_indices])\n",
    "\n",
    "        if len(keep_indices):\n",
    "            keep_indices = torch.cat(keep_indices)\n",
    "        else:\n",
    "            keep_indices = torch.tensor([], dtype=torch.long, device=boxes.device)\n",
    "\n",
    "        # Gather filtered predictions\n",
    "        filtered = {\n",
    "            \"boxes\": boxes_norm[keep_indices],  # Keep normalized format consistent if you want\n",
    "            \"scores\": scores[keep_indices],\n",
    "            \"labels\": labels[keep_indices]\n",
    "        }\n",
    "        nms_batch.append(filtered)\n",
    "\n",
    "    return nms_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daee7990",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, postprocessor, dataloader, device, score_threshold=0.05, img_size=640, apply_nms=False):\n",
    "    \"\"\"\n",
    "    Evaluates the object detection model.\n",
    "    Args:\n",
    "        model (torch.nn.Module): The object detection model to evaluate.\n",
    "        postprocessor (torch.nn.Module): The PostProcessor class to process model output to desired format.\n",
    "        dataloader (torch.utils.data.DataLoader): Dataloader for the validation set.\n",
    "        device (torch.device): The device to run evaluation on (e.g., 'cuda' or 'cpu').\n",
    "        output_path (str): Path to the json file to save the evaluation results.\n",
    "        score_threshold (float): The confidence threshold for model predictions.\n",
    "        img_size (int): Size of the image.\n",
    "        apply_nms (bool): If True apply NMS on postprocessed output.\n",
    "    Returns:\n",
    "        dict: A dictionary containing detailed evaluation metrics.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    metric = MeanAveragePrecision(\n",
    "        box_format=\"xyxy\",\n",
    "        iou_thresholds=[0.50 + 0.05 * i for i in range(10)],\n",
    "        max_detection_thresholds=[1, 10, 100],\n",
    "        class_metrics=True,         # keep per-class AP/AR\n",
    "        extended_summary=True       # keep per-IoU AP & AR\n",
    "    )\n",
    "\n",
    "    for batch, (images, targets) in enumerate(dataloader):\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = postprocessor(outputs, top_k=100, score_thresh=score_threshold)\n",
    "        if apply_nms:\n",
    "            preds = batch_nms(preds, 0.5, img_size)\n",
    "\n",
    "        batch_tgts, batch_preds = [], []\n",
    "\n",
    "        for i in range(len(preds)):\n",
    "            t_boxes  = cxcywh_norm_to_xyxy_abs(targets[i][\"boxes\"], img_size)\n",
    "            t_labels = targets[i][\"labels\"]\n",
    "            batch_tgts.append({\n",
    "                \"boxes\":  t_boxes.to(device),\n",
    "                \"labels\": t_labels.to(device)\n",
    "            })\n",
    "\n",
    "            p_boxes  = cxcywh_norm_to_xyxy_abs(preds[i][\"boxes\"], img_size)\n",
    "            p_scores = preds[i][\"scores\"]\n",
    "            p_labels = preds[i][\"labels\"]\n",
    "            batch_preds.append({\n",
    "                \"boxes\":   p_boxes.to(device),\n",
    "                \"scores\":  p_scores.to(device),\n",
    "                \"labels\":  p_labels.to(device)\n",
    "            })\n",
    "\n",
    "        metric.update(batch_preds, batch_tgts)\n",
    "        print(f\"{batch+1} done.\", end=\"\\r\")\n",
    "\n",
    "    stats = metric.compute()\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9e058b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 done.\r"
     ]
    }
   ],
   "source": [
    "if APPLY_NMS:\n",
    "    evaluation_results = evaluate(model, output_processor, val_loader, DEVICE, 0.05, 640, APPLY_NMS)\n",
    "else:\n",
    "    evaluation_results = evaluate(model, output_processor, val_loader, DEVICE, 0.05, 640, APPLY_NMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "181853d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "result[\"map\"] = evaluation_results[\"map\"].item()\n",
    "result[\"map_50\"] = evaluation_results[\"map_50\"].item()\n",
    "result[\"map_75\"] = evaluation_results[\"map_75\"].item()\n",
    "result[\"map_small\"] = evaluation_results[\"map_small\"].item()\n",
    "result[\"map_medium\"] = evaluation_results[\"map_medium\"].item()\n",
    "result[\"map_large\"] = evaluation_results[\"map_large\"].item()\n",
    "\n",
    "if APPLY_NMS:\n",
    "    with open(\"./saved/evaluation_rtdetr_r18_with_nms.json\", 'w') as f:\n",
    "        json.dump(result, f, indent=4)\n",
    "else:\n",
    "    with open(\"./saved/evaluation_rtdetr_r18_without_nms.json\", 'w') as f:\n",
    "        json.dump(result, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9f9ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
